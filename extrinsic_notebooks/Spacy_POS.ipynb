{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZp05dvGroDf",
        "outputId": "0621689c-0c6a-458a-d41b-c99adbfd4c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej7Ek6al8eGf",
        "outputId": "a768efdc-7766-4c77-d42d-7374c835b42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'UD_Ukrainian-IU'...\n",
            "remote: Enumerating objects: 381, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 381 (delta 23), reused 32 (delta 12), pack-reused 338\u001b[K\n",
            "Receiving objects: 100% (381/381), 12.36 MiB | 13.37 MiB/s, done.\n",
            "Resolving deltas: 100% (241/241), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/UniversalDependencies/UD_Ukrainian-IU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M57oJbWtRFO"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3D0QQc7sCdp",
        "outputId": "3813e64e-ae38-4a89-fcde-06940788fa3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (5496 documents): /tmp/uk_iu-ud-train.spacy\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (892 documents): /tmp/uk_iu-ud-test.spacy\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (672 documents): /tmp/uk_iu-ud-dev.spacy\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy convert --converter conllu\t/content/UD_Ukrainian-IU/uk_iu-ud-train.conllu /tmp\n",
        "!python -m spacy convert --converter conllu /content/UD_Ukrainian-IU/uk_iu-ud-test.conllu /tmp\n",
        "!python -m spacy convert --converter conllu /content/UD_Ukrainian-IU/uk_iu-ud-dev.conllu /tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHr-5jootsPw",
        "outputId": "29f1a90d-7bc4-40a5-96f4-cc650fe11874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.2.1                         \n",
            "Location         /usr/local/lib/python3.7/dist-packages/spacy\n",
            "Platform         Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Python version   3.7.12                        \n",
            "Pipelines                                      \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2ZkhRLjftzC"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAM_cDixaHsX",
        "outputId": "ba5caea5-12b3-465e-af32-fdd43adb1491"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3854, done.\u001b[K\n",
            "remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n",
            "Receiving objects: 100% (3854/3854), 8.22 MiB | 25.14 MiB/s, done.\n",
            "Resolving deltas: 100% (2417/2417), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcLwxtkYaSq2",
        "outputId": "096c2c0f-1c27-44b9-ad5e-87550137744e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /content/fastText\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.1-py2.py3-none-any.whl (211 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3121756 sha256=21c64f75b081915135f6227cfe8f32133dfedf3cf09ce3104850d18caa01c98c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o1cki07c/wheels/22/04/6e/b3aba25c1a5845898b5871a0df37c2126cb0cc9326ad0c08e7\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.1\n"
          ]
        }
      ],
      "source": [
        "!cd fastText && pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E_GUUhhaiYB"
      },
      "outputs": [],
      "source": [
        "from fasttext import load_model\n",
        "import argparse\n",
        "import errno\n",
        "\n",
        "def convert_bin_to_vec(model, output):\n",
        "    f = load_model(model)\n",
        "    words = f.get_words()\n",
        "    with open(output, \"w\") as fp_out:\n",
        "        fp_out.write(str(len(words)) + \" \" + str(f.get_dimension()) + \"\\n\")\n",
        "        for w in words:\n",
        "            v = f.get_word_vector(w)\n",
        "            vstr = \"\"\n",
        "            for vi in v:\n",
        "                vstr += \" \" + str(vi)\n",
        "            try:\n",
        "                fp_out.write(w + vstr + \"\\n\")\n",
        "            except IOError as e:\n",
        "                if e.errno == errno.EPIPE:\n",
        "                    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsuuA2gyHcpj"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/SpaCyResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cdh_QQXgS4u_"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "from glob import glob\n",
        "\n",
        "!mkdir /content/SpaCyResults/\n",
        "\n",
        "for f in glob(\"/gdrive/MyDrive/UberGrid/vectors/*\"):\n",
        "    bf, _ = os.path.splitext(os.path.basename(f))\n",
        "\n",
        "    if os.path.exists(f\"/gdrive/MyDrive/extrinsic/SpacyResults/POS/{bf}\"):\n",
        "        print(f\"Skipping {bf} as their already exists\")\n",
        "        continue\n",
        "    \n",
        "    os.mkdir(f\"/gdrive/MyDrive/extrinsic/SpacyResults/POS/{bf}\")\n",
        "\n",
        "\n",
        "    print(f\"Converting vectors from {bf}\")\n",
        "\n",
        "    !rm -rf /content/FastText\n",
        "    !mkdir /content/FastText\n",
        "    txt_vectors = os.path.join(\"/content/FastText/\", bf + \".vec\")\n",
        "\n",
        "    convert_bin_to_vec(f, txt_vectors)\n",
        "    !python -m spacy init vectors uk {txt_vectors} /content/FastText\n",
        "\n",
        "    !python -m spacy train /gdrive/MyDrive/extrinsic/SpacyResults/POS/pos_tag_config.cfg --output /content/SpaCyResults/{bf} --gpu-id 0\n",
        "    !rm -rf /content/SpaCyResults/{bf}/model-last\n",
        "    !mv -v /content/SpaCyResults/{bf}/* /gdrive/MyDrive/extrinsic/SpacyResults/POS/{bf}/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC42LDhlS-KU",
        "outputId": "b968e714-ec83-4fff-bf15-f11e72d5ce7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cannot parse filename ubertext.fiction_news_wikipedia.filter_rus+short.tokens.txt.d300.subword2-5.cbow_weighted.epoch5\n",
            "Cannot parse filename ubertext.fiction_news_wikipedia.filter_rus+short.tokens.txt.d300.subword2-5.cbow_weighted.epoch10\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "from csv import DictWriter\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "from glob import glob\n",
        "import json\n",
        "\n",
        "mask = r\"algo-([^.]+)\\.epochs-(\\d+)\\.subwords-(\\d+)\\.\\.(\\d+)\\.wordngram-(\\d+).neg_sampling-(\\d+)\"\n",
        "\n",
        "weighed = r\"subword(\\d+)-(\\d+)\\.cbow_weighted.epoch(\\d+)\"\n",
        "\n",
        "\n",
        "results_path = Path(\"/gdrive/MyDrive/SpaCyResults/\")\n",
        "\n",
        "with (results_path / \"extrinsic_eval.csv\").open(\"w\") as fp_out:\n",
        "    w = DictWriter(fp_out, fieldnames=[\"vectors_file\", \"vectors_params\", \"ents_f\", \"ents_p\", \"ents_r\"])\n",
        "\n",
        "    w.writeheader()\n",
        "\n",
        "    for f in glob(\"/gdrive/MyDrive/UberGrid/vectors/*\"):\n",
        "        bf, _ = os.path.splitext(os.path.basename(f))\n",
        "        meta_file = results_path / bf / \"model-best/meta.json\"\n",
        "        if not os.path.exists(meta_file):\n",
        "            print(f\"Cannot find file {meta_file}, skipping\")\n",
        "            continue\n",
        "\n",
        "        m = re.search(mask, bf)\n",
        "        if not m or not (re.search(weighed, bf)):\n",
        "            print(f\"Cannot parse filename {bf}\")\n",
        "            continue\n",
        "\n",
        "        groups = m.groups()\n",
        "\n",
        "        with open(meta_file, \"r\") as fp:\n",
        "            meta = json.load(fp)\n",
        "\n",
        "        w.writerow({\n",
        "            \"vectors_file\": bf,\n",
        "            \"vectors_params\": f\"{groups[0]};{groups[1]};{groups[2]}-{groups[3]};{groups[4]};{groups[5]}\",\n",
        "            \"ents_f\": meta[\"performance\"][\"ents_f\"],\n",
        "            \"ents_p\": meta[\"performance\"][\"ents_p\"],\n",
        "            \"ents_r\": meta[\"performance\"][\"ents_r\"],\n",
        "        })"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}