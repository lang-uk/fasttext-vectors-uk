{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZp05dvGroDf",
        "outputId": "09bc72bb-2dc6-4098-a967-90853c08eeba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M57oJbWtRFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d86f3e-e61f-46b7-ed18-9467f5c7e658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:15:53tcmalloc: large alloc 1147494400 bytes == 0x39818000 @  0x7f6105f39615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.3 MB/s eta 0:12:30tcmalloc: large alloc 1434370048 bytes == 0x7de6e000 @  0x7f6105f39615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.1 MB/s eta 0:10:23tcmalloc: large alloc 1792966656 bytes == 0x2ca0000 @  0x7f6105f39615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.3 MB/s eta 0:04:35tcmalloc: large alloc 2241208320 bytes == 0x6da88000 @  0x7f6105f39615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf33ea000 @  0x7f6105f381e7 0x4b2150 0x4b21dc 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x1e1368000 @  0x7f6105f39615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x4ba899 0x4d29f9\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 7.2 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade spacy\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3D0QQc7sCdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6b1e90-36a2-47be-e3d0-4036c3305a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (4045 documents): /tmp/test.spacy\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n",
            "into documents with `-n 10`.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (8762 documents): /tmp/train.spacy\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy convert /gdrive/MyDrive/NER_UK/fixed-split/test.iob /tmp\n",
        "!python -m spacy convert /gdrive/MyDrive/NER_UK/fixed-split/train.iob /tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAM_cDixaHsX",
        "outputId": "e7557506-0745-4e4c-ce28-863558749d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3930, done.\u001b[K\n",
            "remote: Counting objects: 100% (943/943), done.\u001b[K\n",
            "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
            "remote: Total 3930 (delta 854), reused 806 (delta 806), pack-reused 2987\u001b[K\n",
            "Receiving objects: 100% (3930/3930), 8.24 MiB | 23.64 MiB/s, done.\n",
            "Resolving deltas: 100% (2505/2505), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/fastText\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3157247 sha256=206da1f3700ab29333de95b380998f7266b2efa2582251c60cbadeb8d5926ae9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qne2_sae/wheels/22/04/6e/b3aba25c1a5845898b5871a0df37c2126cb0cc9326ad0c08e7\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!cd fastText && pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E_GUUhhaiYB"
      },
      "outputs": [],
      "source": [
        "from fasttext import load_model\n",
        "import argparse\n",
        "import errno\n",
        "\n",
        "def convert_bin_to_vec(model, output):\n",
        "    f = load_model(model)\n",
        "    words = f.get_words()\n",
        "    with open(output, \"w\") as fp_out:\n",
        "        fp_out.write(str(len(words)) + \" \" + str(f.get_dimension()) + \"\\n\")\n",
        "        for w in words:\n",
        "            v = f.get_word_vector(w)\n",
        "            vstr = \"\"\n",
        "            for vi in v:\n",
        "                vstr += \" \" + str(vi)\n",
        "            try:\n",
        "                fp_out.write(w + vstr + \"\\n\")\n",
        "            except IOError as e:\n",
        "                if e.errno == errno.EPIPE:\n",
        "                    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-xMi66LbRvi"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "!mkdir /content/SpaCyResults/\n",
        "f = \"/gdrive/MyDrive/UberGrid/vectors/cbow_weighted/baseline_skipgram.bin\"\n",
        "bf, _ = os.path.splitext(os.path.basename(f))\n",
        "\n",
        "if not os.path.exists(f\"/gdrive/MyDrive/SpaCyResults/{bf}\"):\n",
        "    !rm -rf /content/FastText\n",
        "    !mkdir /content/FastText\n",
        "    txt_vectors = os.path.join(\"/content/FastText/\", bf + \".vec\")\n",
        "\n",
        "    convert_bin_to_vec(f, txt_vectors)\n",
        "    !python -m spacy init vectors uk {txt_vectors} /content/FastText\n",
        "\n",
        "    !python -m spacy train /gdrive/MyDrive/SpaCyResults/ner_uk_cpu_init.config --output /content/SpaCyResults/{bf} --gpu-id 0\n",
        "    !rm -rf /content/SpaCyResults/{bf}/model-last\n",
        "    !mv /content/SpaCyResults/{bf} /gdrive/MyDrive/SpaCyResults/\n",
        "\n",
        "!rm -rf /content/SpaCyResults/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgk2rilHlaE-",
        "outputId": "2eae9fc2-5339-42bd-dda6-f3c45cfc341a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting vectors from ubertext2.0.skipgrams.champion\n",
            "\u001b[38;5;4mℹ Creating blank nlp object for language 'uk'\u001b[0m\n",
            "[2022-09-27 13:12:29,039] [INFO] Reading vectors from /content/FastText/ubertext2.0.skipgrams.champion.vec\n",
            "INFO:spacy:Reading vectors from /content/FastText/ubertext2.0.skipgrams.champion.vec\n",
            "4398076it [00:36, 120612.62it/s]\n",
            "[2022-09-27 13:13:05,801] [INFO] Loaded vectors from /content/FastText/ubertext2.0.skipgrams.champion.vec\n",
            "INFO:spacy:Loaded vectors from /content/FastText/ubertext2.0.skipgrams.champion.vec\n",
            "\u001b[38;5;2m✔ Successfully converted 4398076 vectors\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved nlp object with vectors to output directory. You can now use\n",
            "the path to it in your config as the 'vectors' setting in [initialize].\u001b[0m\n",
            "/content/FastText\n",
            "\u001b[38;5;2m✔ Created output directory:\n",
            "/content/SpaCyResults/ubertext2.0.skipgrams.champion\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/SpaCyResults/ubertext2.0.skipgrams.champion\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-09-27 13:15:20,854] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-09-27 13:15:20,864] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "INFO:spacy:Pipeline: ['tok2vec', 'ner']\n",
            "[2022-09-27 13:15:20,868] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "tcmalloc: large alloc 1265852416 bytes == 0xfda9c000 @  0x7f20e701b1e7 0x4b2150 0x7f20dc17b197 0x7f20dc17b782 0x7f20dc17bb73 0x7f20dc17a95e 0x7f20dc17aab7 0x58ec54 0x51b4e6 0x7f1edd675878 0x7f1edd6762de 0x7f1edd678637 0x7f1edd678970 0x7f1edc26237a 0x7f1edc27bde3 0x58ed05 0x51babb 0x5b4a3e 0x58f49e 0x51740e 0x58f2a7 0x51b221 0x5b4a3e 0x58f49e 0x51837f 0x5b4a3e 0x4ba80a 0x51908c 0x5b4a3e 0x58f49e 0x51837f\n",
            "[2022-09-27 13:15:34,273] [INFO] Added vectors: /content/FastText\n",
            "INFO:spacy:Added vectors: /content/FastText\n",
            "[2022-09-27 13:15:36,576] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "[2022-09-27 13:15:56,855] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "INFO:spacy:Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0005\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     46.94    0.00    0.00    0.00    0.00\n",
            "  0     200          5.41   1075.58   60.26   81.55   47.79    0.60\n",
            "  0     400         24.98    593.55   66.91   66.89   66.94    0.67\n",
            "  0     600         30.25    682.13   73.54   80.25   67.87    0.74\n",
            "  0     800         47.08    838.56   73.13   74.53   71.78    0.73\n",
            "  0    1000         69.58    808.57   75.38   75.76   75.00    0.75\n",
            "  1    1200         74.33    870.66   75.86   79.01   72.95    0.76\n",
            "  1    1400         78.17    896.12   73.96   77.57   70.66    0.74\n",
            "  2    1600         86.62    787.29   77.95   77.87   78.02    0.78\n",
            "  3    1800         80.94    851.98   77.47   79.25   75.78    0.77\n",
            "  3    2000        123.44    658.87   78.01   81.18   75.08    0.78\n",
            "  4    2200        132.53    774.66   77.91   79.11   76.74    0.78\n",
            "  6    2400        159.56    588.18   77.73   80.18   75.43    0.78\n",
            "  7    2600         99.51    359.18   75.74   76.61   74.88    0.76\n",
            "  8    2800         63.56    212.92   79.59   80.44   78.76    0.80\n",
            "  9    3000        109.57    222.70   77.89   78.30   77.48    0.78\n",
            " 11    3200        101.69    161.50   77.91   80.38   75.58    0.78\n",
            " 12    3400         69.58    104.78   76.91   77.72   76.12    0.77\n",
            " 13    3600        113.01    107.61   77.70   78.36   77.05    0.78\n",
            " 14    3800         83.31     70.07   77.96   79.47   76.51    0.78\n",
            " 15    4000         82.35     97.12   77.96   78.25   77.67    0.78\n",
            " 17    4200        174.41    144.01   76.43   78.99   74.03    0.76\n",
            " 18    4400        141.11    119.86   77.45   77.49   77.40    0.77\n",
            " 19    4600        147.56    123.75   77.09   78.95   75.31    0.77\n",
            " 20    4800        126.51     87.79   76.67   77.71   75.66    0.77\n",
            " 22    5000         84.77     62.39   76.17   78.09   74.34    0.76\n",
            " 23    5200        141.10     93.81   78.22   79.88   76.63    0.78\n",
            " 24    5400        443.83    156.65   77.86   79.81   76.01    0.78\n",
            " 25    5600        527.05    170.69   75.23   77.41   73.18    0.75\n",
            " 27    5800         96.95     68.78   76.45   78.30   74.69    0.76\n",
            " 28    6000        127.54     81.83   76.68   77.54   75.85    0.77\n",
            " 29    6200         72.23     41.14   75.28   77.24   73.41    0.75\n",
            " 30    6400        157.66     73.81   75.69   77.29   74.15    0.76\n",
            " 32    6600         87.81     56.91   74.60   75.58   73.64    0.75\n",
            " 33    6800         91.46     53.25   77.19   78.05   76.36    0.77\n",
            " 34    7000        131.07     79.40   77.37   78.58   76.20    0.77\n",
            " 35    7200         73.20     40.41   77.64   79.17   76.16    0.78\n",
            " 37    7400        168.07     66.02   76.89   77.51   76.28    0.77\n",
            " 38    7600         49.24     25.05   76.97   78.96   75.08    0.77\n",
            " 39    7800         66.75     31.29   76.80   77.25   76.36    0.77\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/SpaCyResults/ubertext2.0.skipgrams.champion/model-last\n",
            "Converting vectors from ubertext2.0.cbow.champion\n",
            "\u001b[38;5;4mℹ Creating blank nlp object for language 'uk'\u001b[0m\n",
            "[2022-09-27 13:45:16,224] [INFO] Reading vectors from /content/FastText/ubertext2.0.cbow.champion.vec\n",
            "INFO:spacy:Reading vectors from /content/FastText/ubertext2.0.cbow.champion.vec\n",
            "4398076it [00:41, 106290.14it/s]\n",
            "[2022-09-27 13:45:57,910] [INFO] Loaded vectors from /content/FastText/ubertext2.0.cbow.champion.vec\n",
            "INFO:spacy:Loaded vectors from /content/FastText/ubertext2.0.cbow.champion.vec\n",
            "\u001b[38;5;2m✔ Successfully converted 4398076 vectors\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved nlp object with vectors to output directory. You can now use\n",
            "the path to it in your config as the 'vectors' setting in [initialize].\u001b[0m\n",
            "/content/FastText\n",
            "\u001b[38;5;2m✔ Created output directory:\n",
            "/content/SpaCyResults/ubertext2.0.cbow.champion\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/SpaCyResults/ubertext2.0.cbow.champion\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-09-27 13:48:33,591] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-09-27 13:48:33,603] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "INFO:spacy:Pipeline: ['tok2vec', 'ner']\n",
            "[2022-09-27 13:48:33,609] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "tcmalloc: large alloc 1265852416 bytes == 0xfcc54000 @  0x7f16e2b411e7 0x4b2150 0x7f16d7ca1197 0x7f16d7ca1782 0x7f16d7ca1b73 0x7f16d7ca095e 0x7f16d7ca0ab7 0x58ec54 0x51b4e6 0x7f14d919a878 0x7f14d919b2de 0x7f14d919d637 0x7f14d919d970 0x7f14c3d8737a 0x7f14c3da0de3 0x58ed05 0x51babb 0x5b4a3e 0x58f49e 0x51740e 0x58f2a7 0x51b221 0x5b4a3e 0x58f49e 0x51837f 0x5b4a3e 0x4ba80a 0x51908c 0x5b4a3e 0x58f49e 0x51837f\n",
            "[2022-09-27 13:48:49,009] [INFO] Added vectors: /content/FastText\n",
            "INFO:spacy:Added vectors: /content/FastText\n",
            "[2022-09-27 13:48:51,615] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "[2022-09-27 13:49:01,849] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "INFO:spacy:Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0005\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     46.94    0.00    0.00    0.00    0.00\n",
            "  0     200          8.81   1193.18   58.09   62.71   54.11    0.58\n",
            "  0     400        103.77    618.83   65.42   65.07   65.78    0.65\n",
            "  0     600         25.07    654.48   73.04   76.44   69.92    0.73\n",
            "  0     800         37.12    861.27   75.33   78.68   72.25    0.75\n",
            "  0    1000         32.74    792.87   77.52   77.64   77.40    0.78\n",
            "  1    1200         78.33    873.53   77.35   78.49   76.24    0.77\n",
            "  1    1400         74.11   1030.28   76.93   77.68   76.20    0.77\n",
            "  2    1600         61.86    858.10   78.87   79.26   78.49    0.79\n",
            "  3    1800         78.76   1026.62   79.73   83.47   76.32    0.80\n",
            "  3    2000         87.91    921.23   80.99   82.34   79.69    0.81\n",
            "  4    2200        165.47    953.94   80.68   82.62   78.84    0.81\n",
            "  6    2400         85.80    698.02   78.79   80.23   77.40    0.79\n",
            "  7    2600        119.55    682.77   79.98   82.79   77.36    0.80\n",
            "  8    2800         95.31    486.53   79.76   81.06   78.49    0.80\n",
            "  9    3000        123.07    446.91   78.52   79.27   77.79    0.79\n",
            " 11    3200        105.94    313.02   79.37   80.10   78.64    0.79\n",
            " 12    3400        115.21    291.89   76.92   78.11   75.78    0.77\n",
            " 13    3600        100.45    175.11   79.40   81.51   77.40    0.79\n",
            " 14    3800        160.82    224.73   80.33   81.63   79.07    0.80\n",
            " 15    4000        145.03    206.54   77.40   80.72   74.34    0.77\n",
            " 17    4200        119.76    173.22   79.67   80.44   78.91    0.80\n",
            " 18    4400        124.34    171.42   78.07   79.83   76.40    0.78\n",
            " 19    4600        156.20    186.78   78.93   79.90   77.98    0.79\n",
            " 20    4800        306.64    193.10   78.88   81.40   76.51    0.79\n",
            " 22    5000        148.64    152.19   78.94   81.14   76.86    0.79\n",
            " 23    5200        137.31    139.95   78.30   79.37   77.25    0.78\n",
            " 24    5400        149.38    133.44   78.14   80.18   76.20    0.78\n",
            " 25    5600        180.56    155.13   79.16   81.69   76.78    0.79\n",
            " 27    5800        123.74    108.52   78.53   80.37   76.78    0.79\n",
            " 28    6000         96.36     79.93   79.74   82.13   77.48    0.80\n",
            " 29    6200        214.32    157.73   80.14   80.92   79.38    0.80\n",
            " 30    6400        234.89    164.02   79.37   80.18   78.57    0.79\n",
            " 32    6600        205.14    136.15   78.45   79.98   76.98    0.78\n",
            " 33    6800        223.62    121.61   78.80   80.53   77.13    0.79\n",
            " 34    7000        172.15    104.32   78.63   80.23   77.09    0.79\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/SpaCyResults/ubertext2.0.cbow.champion/model-last\n"
          ]
        }
      ],
      "source": [
        "import os.path\n",
        "from glob import glob\n",
        "\n",
        "!mkdir /content/SpaCyResults/\n",
        "\n",
        "for f in glob(\"/gdrive/MyDrive/UberGrid/UberText_punct/*.bin\"):\n",
        "    bf, _ = os.path.splitext(os.path.basename(f))\n",
        "\n",
        "    if os.path.exists(f\"/gdrive/MyDrive/UberGrid/UberText_punct/SpacyEval/{bf}\"):\n",
        "        print(f\"Skipping {bf} as their already exists\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Converting vectors from {bf}\")\n",
        "\n",
        "    !rm -rf /content/FastText\n",
        "    !mkdir /content/FastText\n",
        "    txt_vectors = os.path.join(\"/content/FastText/\", bf + \".vec\")\n",
        "\n",
        "    convert_bin_to_vec(f, txt_vectors)\n",
        "    !python -m spacy init vectors uk {txt_vectors} /content/FastText\n",
        "\n",
        "    !python -m spacy train /gdrive/MyDrive/SpaCyResults/ner_uk_cpu_init.config --output /content/SpaCyResults/{bf} --gpu-id 0\n",
        "    !rm -rf /content/SpaCyResults/{bf}/model-last\n",
        "    !mv /content/SpaCyResults/{bf} /gdrive/MyDrive/UberGrid/UberText_punct/SpacyEval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QC42LDhlS-KU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "from csv import DictWriter\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "from glob import glob\n",
        "import json\n",
        "\n",
        "mask = r\"algo-([^.]+)\\.epochs-(\\d+)\\.subwords-(\\d+)\\.\\.(\\d+)\\.wordngram-(\\d+).neg_sampling-(\\d+)\"\n",
        "\n",
        "weighed = r\"subword(\\d+)-(\\d+)\\.cbow_weighted.epoch(\\d+)\"\n",
        "\n",
        "\n",
        "results_path = Path(\"/gdrive/MyDrive/UberGrid/UberText_punct/SpacyEval/\")\n",
        "\n",
        "with (results_path / \"extrinsic_eval_punct.csv\").open(\"w\") as fp_out:\n",
        "    w = DictWriter(fp_out, fieldnames=[\"vectors_file\", \"vectors_params\", \"ents_f\", \"ents_p\", \"ents_r\"])\n",
        "\n",
        "    w.writeheader()\n",
        "\n",
        "    for f in glob(\"/gdrive/MyDrive/UberGrid/UberText_punct/*.bin\"):\n",
        "        bf, _ = os.path.splitext(os.path.basename(f))\n",
        "        meta_file = results_path / bf / \"model-best/meta.json\"\n",
        "        if not os.path.exists(meta_file):\n",
        "            print(f\"Cannot find file {meta_file}, skipping\")\n",
        "            continue\n",
        "\n",
        "        m = re.search(mask, bf)\n",
        "        if not m or not (re.search(weighed, bf)):\n",
        "           print(f\"Cannot parse filename {bf}\")\n",
        "           continue\n",
        "\n",
        "        groups = m.groups()\n",
        "\n",
        "        with open(meta_file, \"r\") as fp:\n",
        "            meta = json.load(fp)\n",
        "\n",
        "        w.writerow({\n",
        "            \"vectors_file\": bf,\n",
        "            \"vectors_params\": f\"{groups[0]};{groups[1]};{groups[2]}-{groups[3]};{groups[4]};{groups[5]}\",\n",
        "            \"ents_f\": meta[\"performance\"][\"ents_f\"],\n",
        "            \"ents_p\": meta[\"performance\"][\"ents_p\"],\n",
        "            \"ents_r\": meta[\"performance\"][\"ents_r\"],\n",
        "        })"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}